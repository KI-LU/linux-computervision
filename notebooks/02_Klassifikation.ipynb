{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4bcbbb9-0069-4105-af03-af847a45697a",
   "metadata": {},
   "source": [
    "# Bildklassifikation\n",
    "\n",
    "Bildklassifikation ist eines der Grundprobleme des Bereichs **Computer Vision**. Es bildet die Basis für viele fortgeschrittenere Aufgaben, wie z.B. Objekterkennung. \n",
    "\n",
    "Die Ausgabe eines Bildklassifizierers ist eine einzelne Klassenbezeichnung und ein Konfidenzwert. Die Bildklassifizierung ist nützlich, wenn Sie nur wissen müssen, zu welcher Klasse ein Bild gehört, und nicht wissen müssen, wo sich die Objekte dieser Klasse befinden oder welche Form sie genau haben.\n",
    "\n",
    "![Image](../beispielbilder/grafiken/image-classification-deeplearning.jpg)\n",
    "\n",
    "In diesem Notebook werden Sie selbstständig einen Bildklassifizierer auf einem eigenen Datensatz trainieren und evaluieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe6e7f0-cb3e-4d49-9faa-f41d9eba7ab7",
   "metadata": {},
   "source": [
    "Um das Verständnis zu vertiefen und um auf wichtige Aspekte aufmerksam zu machen haben wir eine Reihe von Fragen und Aufgaben in dieses Notebook eingebaut:\n",
    "\n",
    "**Beispiel**\n",
    "\n",
    "1. **Verständnisfragen**\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Frage:</b> In den blauen Boxen stehen Verständnisfragen</div>\n",
    "\n",
    "2. **Arbeitsaufträge**\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Auftrag:</b> In grünen Boxen finden sich Arbeitsaufträge.</div>\n",
    "\n",
    "3. **Optionale Inhalte**\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Optional:</b> In gelben Boxen finden Sie optionale Inhalte.</div>\n",
    "\n",
    "Besonders komplizierte Aspekte oder Bereiche, in denen leicht Fehler gemacht werden können sind mit einer roten Box gekennzeichnet:\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Achtung:</b> Hier müssen Sie gut aufpassen. Nehmen Sie sich ausreichend Zeit, die nachfolgenden Angaben zu lesen oder Fragen Sie ein Mitglied des Teams um Hilfe.</div>\n",
    "\n",
    "**Was *ist* Bildklassifikation?**\n",
    "\n",
    "Da es sich hierbei um ein Problem des **überwachten Lernens** <a href=\"https://de.wikipedia.org/wiki/%C3%9Cberwachtes_Lernen\"> (zur Auffrischung) </a> handelt, reicht es nicht einfach, dem Algorithmus nur die Bilddaten zuzuführen. Damit eine Zuordnung von Bild &rarr; Label stattfinden kann, müssen die Daten entsprechend **annotiert** sein. \n",
    "\n",
    "*Wichtig*: Nicht **alle** Spielarten der Bildklassifizierung sind Teil des überwachten Lernens. Die gängigsten Formen sind es aber, und so auch die Aufgabe, die Sie heute lösen werden.\n",
    "\n",
    "<details>\n",
    "    <summary><b>Exkurs: Algorithmendesign vs. Datenkuration</b></summary>\n",
    "    <h5>Wo liegen heute die Constraints?</h5>\n",
    "\n",
    "In vielen Bereichen des Deep Learning spielt das Design der Algorithmen heute nicht mehr die Hauptrolle. Insbesondere in der maschinellen              Bildverarbeitung, also <b>Computer Vision</b> sind die <i>besten</i> (oder zumindest: sehr gute) Algorithmen heute bekannt. Der Constraint für die     Performance der Modelle liegt also heute weniger im Bereich der Architektur, sondern mehr in der Qualität der Datensätze. \n",
    "    \n",
    "Ex-Tesla AI Direktor und Gründungsmitglied von OpenAI, Andrej Karpathy, zum Thema Datensatzqualität: <a href=\"https://youtu.be/PlLmdTcsAWU?si=7QmHbQ5oHrBP2hI6&t=2341\"> Zum Interview (ab ca. Min 39:00)</a>\n",
    "    \n",
    "    \n",
    "</details>\n",
    "<br>\n",
    "\n",
    "In diesem Notebook widmen wir uns also zwei Dingen:\n",
    "\n",
    "1. **Dem Sammeln von Bilddaten**\n",
    "2. **Finetuning eines SOTA-Bildklassifikators**\n",
    "\n",
    "*SOTA = State-of-the-art*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4a4b35-51aa-49be-8e9c-d481c39c8023",
   "metadata": {},
   "source": [
    "## 1.1. Importieren der notwendigen Bibliotheken und Funktionen\n",
    "\n",
    "Um das Bildklassifikations-Problem zu lösen, greifen wir auf ein **vortrainiertes** Modell der YOLO-Reihe zurück.\n",
    "Eigentlich für die Modelle zur Objekterkennung bekannt, bietet YOLO auch Modelle für die Klassifizierung von Bildern. YOLO steht für:\n",
    "\n",
    "* **Y**ou\n",
    "* **O**nly\n",
    "* **L**ook\n",
    "* **O**nce\n",
    "\n",
    "Die YOLO-Modellarchitektur ermöglicht die schnelle und effiziente Erkennung von Objekten in Bildern und Videos. Im Gegensatz zu anderen Methoden benötigt YOLO nur einen Durchgang, um alle Objekte zu identifizieren. Es berücksichtigt unterschiedliche Objektgrößen und bietet Vielseitigkeit für verschiedene Anwendungen. YOLO zeichnet sich durch seine Geschwindigkeit und Fähigkeit aus, komplexe Szenen in einem Schritt zu erfassen.\n",
    "\n",
    "Wenn Sie mehr über die YOLO-Modelle lesen möchten, finden Sie <a href=\"https://blog.roboflow.com/guide-to-yolo-models/\">hier</a> einen guten Blog-Artikel und <a href=\"https://docs.ultralytics.com/\">hier</a> die Ultralytics-Dokumentation zum YOLOv8-Modell.\n",
    "\n",
    "Zur Verwendung des Modells und für das Aufbereiten der Bilder benötigen Sie eine Reihe von Bibliotheken und Hilfsfunktionen. Die nachfolgende Codezelle importiert all diese Abhängigkeiten in das Projekt.\n",
    "\n",
    "<div class=\"alert block\" style=\"background-color: #D3D3D3;\">\n",
    "<b>Info:</b> Kürzlich wurde eine neue Version des Modells veröffentlicht: YOLOv10!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84460cf-c8df-459f-83e8-8927df397bbe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Auftrag:</b> Führen Sie die nachfolgende Codezelle mit einem Klick auf den Play-Button aus.</div>\n",
    "\n",
    "![Image](../beispielbilder/grafiken/play.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89132b71-c967-4851-aca6-8498751ea1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO                                 # Für Zugriff auf die YOLO-Modelle\n",
    "import os                                                    # Zugriff auf die Funktionen des Betriebssystems\n",
    "\n",
    "# Die folgenden Funktionen dienen der Unterstützung beim Erstellen der Daten und der Verwendung des Modells\n",
    "###########################################################################################################\n",
    "from helpers.image_helpers import capture_images             # Helferfunktion zum Aufnehmen der Bilder\n",
    "from helpers.model_helpers import inference_webcam           # Helferfunktion zum Anwenden des Modells mit der Webcam\n",
    "from helpers.model_helpers import choose_model               # Helferfunktion zur Auswahl des Modells\n",
    "from helpers.model_helpers import set_training_config        # Helferfunktion zum Einstellen der Trainingskonfiguration\n",
    "from helpers.file_handlers import prepare_folder_structure   # Helferfunktion zum Erstellen der benötigten Ordnerstruktur\n",
    "from helpers.file_handlers import create_config              # Helferfunktion zum Erstellen der Konfigurationsdatei\n",
    "from helpers.config import set_metadata                      # Helferfunktion zum Erstellen des Ordners\n",
    "from helpers.config import set_image_data                    # Helferfunktion zum Erstellen des Ordners\n",
    "TASK = 'CLS'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e583393-dee6-4ad5-8171-c513fe6070cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Optional:</b> Auch wenn Sie in diesem Notebook keinen eigenen Code schreiben müssen, ist für ein tieferes Verständnis der Vorgänge ein gewisses Verständnis von Code unabdingbar. Wenn es Sie interessiert oder Sie einfach gerne tiefer in die Materie eintauchen wollen, finden Sie im Ordner <code>notebooks/helpers</code> die Hilfsfunktionen, die wir Ihnen zur Verfügung stellen.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b59de0-8f07-4467-ad00-cbc67a85dd60",
   "metadata": {},
   "source": [
    "## 1.2. Festlegen des Gruppennames\n",
    "\n",
    "Ihre Datensätze und Modelle werden gespeichert und können Ihnen im Nachgang auf Wunsch zur Verfügung gestellt werden. \n",
    "Um die Identifikation zu gewährleisten, werden Sie nach Ausführen der nachfolgenden Codezelle dazu aufgefordert, einen Gruppennamen festzulegen. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Auftrag:</b> Führen Sie die nachfolgende Codezelle mit einem Klick auf den Play-Button aus.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac0145-cefc-4b44-9cc3-22748b4f9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP, PATH = set_metadata(TASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5de04b-f539-469e-aa73-646c003133d0",
   "metadata": {},
   "source": [
    "## 1.3. Generieren der Bilddaten (15 min)\n",
    "\n",
    "Nun beginnen wir mit dem Sammeln von Bildern. Die **Datenqualität** ist der entscheidende Faktor bei Machine-Learning-Projekten.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Auftrag:</b> Machen Sie sich gemeinsam Gedanken zu einem Problem, welches Sie lösen wollen. Überlegen Sie außerdem <b>vorher</b> wie gute Daten dafür aussehen müssen. Denken Sie z.B. an Entfernung, Licht, Orientierung, Position, etc. Nehmen Sie sich dafür 15 Minuten Zeit!</div>\n",
    "\n",
    "Sie sollten jetzt einen Plan haben zu:\n",
    "\n",
    "* Anzahl der Bildklassen (z.B. defekt & nicht-defekt => 2 Klassen **oder** Aluprofil, Unterlegscheibe, Sechskant => 3 Klassen)\n",
    "* Anzahl der Bilder pro Klasse (je mehr Klassen, desto mehr Bilder sollten Sie pro Klasse einplanen)\n",
    "* Wie müssen die Bilder aussehen? (Beleuchtung, Ausrichtung der Objekte auf den Bildern, Entfernung zur Kamera, ...)\n",
    "\n",
    "Die nachfolgende Codezelle hilft Ihnen dabei, Bilder aufzunehmen. <br>\n",
    "Nach Ausführen der Zelle werden Sie dazu aufgefordert, den Klassennamen einzugeben, z.B. \"aluprofil\". <br>\n",
    "\n",
    "Außerdem müssen Sie festlegen, wie viele Bilder für diese Klasse aufgenommen werden sollen, z.B. 100 <br>\n",
    "Dann können Sie die Zeit zwischen zwei Aufnahmen festlegen. \n",
    "\n",
    "Jetzt beginnt die Webcam Bilder für diese Klasse aufzunehmen. Diese Bilder werden im Ordner `data/classification/IHR_GRUPPENNAME` gespeichert. \n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Achtung:</b> Sie müssen die Codezelle für jede Klasse einmal ausführen.</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Auftrag:</b> Beginnen Sie jetzt mit dem Sammeln der Daten.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272487d-17c8-4bc4-bdf8-1402bed30920",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NAME, NUM_IMGS, DELAY, DEVICE = set_image_data(TASK)\n",
    "\n",
    "capture_images(num_imgs=NUM_IMGS,\n",
    "               name=NAME,\n",
    "               img_path=PATH,\n",
    "               device=DEVICE,\n",
    "               delay=DELAY,\n",
    "               show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa7d2f-6dc1-4754-864a-b3f9d4260ef1",
   "metadata": {},
   "source": [
    "## 1.4. Aufsetzen der Ordnerstruktur\n",
    "\n",
    "Damit das Modell mit Ihren Daten arbeiten kann, müssen diese in einem bestimmten Format vorliegen. Aktuell befinden sich alle Bilder in einem Ordner. \n",
    "\n",
    "Hier ist die gewünschte Ordnerstruktur:\n",
    "\n",
    "![Image](../beispielbilder/grafiken/ordnerstruktur.PNG)\n",
    "\n",
    "Die Daten werden in **Trainings-**, **Validierungs-** und **Testdaten** aufgetrennt. \n",
    "\n",
    "Das Modell wird zunächst nur auf den **Trainingsdaten** trainiert und anschließend auf den **Validierungsdaten** überprüft. So wird eine **Überanpassung** auf die Trainingsdaten verhindert bzw. erkannt. Eine Überanpassung entspricht in etwa dem Auswendiglernen der Daten. Dann wäre das Modell zwar in der Lage, bereits bekannte Bilder fehlerfrei zu klassifizieren, könnte aber nicht auf ungesehene Daten **generalisieren**. Da das Modell aber in der Produktionsumgebung nicht mit exakt den Daten aus dem Training konfrontiert werden würde, ist eine Überanpassung unbedingt zu verhindern!\n",
    "\n",
    "Erreicht das Modell nach dem Training die gewünschte Leistung, wird es am Ende noch ein letztes Mal auf den **Testdaten** überprüft, bevor es in die Produktionsumgebung überführt werden kann.\n",
    "\n",
    "In jedem der `train`, `val` und `test` Ordner befinden sich jeweils weitere Unterordner für die einzelnen Klassen. Das `YOLO`-Modell wird anhand dieser Unterordner erkennen, welches **Label** ein Bild hat. \n",
    "\n",
    "Die ```prepare_folder_structure(PATH)```-Funktion stellt diese Ordnerstruktur automatisch für Sie her.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Optional:</b> Wenn Sie wissen möchten, wie diese Funktion dies tut, schauen Sie im Ordner <code>notebooks/helpers/misc.py</code> vorbei!</div>\n",
    "\n",
    "Anschließend wird über die `create_config(PATH)`-Funktion die Konfigurationsdatei erstellt, die dem Modell sagt, wo die Daten zu finden sind.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Optional:</b> Auch diese finden Sie im Ordner <code>notebooks/helpers/misc.py</code>.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Auftrag:</b> Führen Sie die nachfolgende Codezelle mit einem Klick auf den Play-Button aus.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab79e97f-9c4a-4847-87d9-036818cdf178",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_folder_structure(PATH, task=TASK)\n",
    "create_config(PATH, task=TASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda1c68-7441-40a6-9dd5-d8a9db79aa07",
   "metadata": {},
   "source": [
    "# 2. Modelltraining\n",
    "\n",
    "Nachdem die Datenvorbereitung abgeschlossen ist, geht es nun daran, das Modell zu trainieren. \n",
    "\n",
    "Dieser Teil besteht aus zwei Schritten:\n",
    "\n",
    "* Auswahl eines geeigneten Modells\n",
    "* Trainieren dieses Modells\n",
    "\n",
    "## 2.1. Modellauswahl\n",
    "\n",
    "Die YOLO-Modelle zur Bildklassifierung kommen in verschiedenen Größen:\n",
    "\n",
    "![Image](../beispielbilder/grafiken/yolo-cls.PNG)\n",
    "\n",
    "Grundsätzlich gilt: Je größer das Modell, desto mächtiger ist es, aber desto langsamer ist es auch (sowohl während des Trainings als auch der Anwendung)\n",
    "\n",
    "Hier müssen Sie entscheiden, ob es Ihnen wichtiger ist, ein sehr performantes Modell zu haben, welches aber etwas langsamer ist, oder ob es Ihnen vor allem auf Geschwindigkeit ankommt und Sie ein paar Abstriche in der Performance machen können.\n",
    "\n",
    "Diese Entscheidung ist immer abhängig vom Einsatzgebiet des Modells. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Auftrag:</b> Führen Sie die nachfolgende Codezelle mit einem Klick auf den Play-Button aus. Sie werden anschließend dazu aufgerodert, ein Modell zu wählen.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367d50c-9fda-4a7d-aeba-923e8f62e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = choose_model(TASK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8d7c9-b981-470f-949e-7127bd81a614",
   "metadata": {},
   "source": [
    "## 2.2. Trainingsfunktion\n",
    "\n",
    "Um das Modell zu trainieren müssen Sie diesem nur mitteilen, wo die Trainingsdaten zu finden sind. Dafür haben Sie vorher die Konfigurationsdatei erzeugt. \n",
    "\n",
    "```Python\n",
    "results = model.train(data=PATH,        # Zeigt auf den Ordner mit der Konfigurationsdatei\n",
    "                      epochs=EPOCHS,    # 1 Epoche = ein Durchlauf aller Daten durch das Modell\n",
    "                      name=NAME,        # Name der einzelnen Trainingsdurchläufe\n",
    "                      project=SAVE_DIR) # Name des Ordners in dem die Modellergebnisse gespeichert werden     \n",
    "```\n",
    "\n",
    "Beim Ausführen der nachfolgenden Codezelle werden Sie dazu aufgefordert die Anzahl der **Trainingsepochen** einzugeben. Wie lange das Modell trainieren soll ist immer Problemabhängig, aber für ein leichtes Problem sollten 20 - 30 Epochen vollkommen ausreichend sein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbecec97-613c-4031-8c30-73126b96b841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS, _, NAME, SAVE_DIR = set_training_config(PATH)\n",
    "\n",
    "results = model.train(data=PATH, \n",
    "                      epochs=EPOCHS, \n",
    "                      name=NAME,\n",
    "                      project=SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74eb898-573c-437e-9487-7eaa49c33595",
   "metadata": {},
   "source": [
    "## 2.3. Evaluieren\n",
    "\n",
    "Nachdem das Modell trainiert wurde, wurde im Ordner `GRUPPENNAME/runs/` automatisch ein Ordner für den Trainingsdurchlauf angelegt. Die Inhalte dieses Ordners sehen folgendermaßen aus:\n",
    "\n",
    "![Image](../beispielbilder/grafiken/eval-cls.PNG)\n",
    "\n",
    "Im `weights`-Ordner befinden sich zwei Dateien: `best.pt` und `last.pt`:\n",
    "\n",
    "* `best.pt` ist der beste Zustand des Modells\n",
    "* `last.pt` ist der letzte Zustand des Modells\n",
    "\n",
    "Je nachdem ob Sie weitertrainieren möchten oder das Modell in die Produktionsumgebung überführen wollen, können Sie mit einer der beiden Dateien weiterarbeiten. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Frage:</b> Warum macht es im Hinblick auf Überanpassung Sinn, immer den besten Zustand des Modells zu speichern?</div>\n",
    "\n",
    "Außerdem enthält der Ordner noch eine Reihe an anderen Dateien:\n",
    "\n",
    "* Konfusionmatrizen\n",
    "* results.png\n",
    "* results.csv\n",
    "* Trainings- und Validationsbatches\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Frage:</b> Nehmen Sie sich Zeit diese Dateien in Ruhe zu betrachten. Welche Informationen können Sie herauslesen?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d984d75-6676-4b70-8272-e720720b6554",
   "metadata": {},
   "source": [
    "# 3. Verwenden des Modells\n",
    "\n",
    "Nun kann das Modell verwendet werden.\n",
    "\n",
    "Wir stellen Ihnen dafür die Hilfsfunktion `inference_webcam` zur Verfügung, welche die Webcam verwendet um einen Stream aufzunehmen und die Frames live zu klassifizieren.\n",
    "\n",
    "Alternativ können Sie aber auch einzelne Bilder klassifizieren. Dafür müssten Sie die Bilddatei einfach dem Modell übergeben:\n",
    "\n",
    "```Python\n",
    "result = model('pfad/zum/bild.jpg')\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Auftrag:</b> Führen Sie die nachfolgende Codezelle mit einem Klick auf den Play-Button aus.</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Achtung:</b> Manchmal öffnet sich das Webcam-Fenster nicht automatisch oder die Webcam wird nicht erkannt. Im ersten Fall können Sie das Fenster unten in der Windows-Taskleiste auswählen. Im zweiten Fall führen Sie die Funktion einfach ein weiteres Mal aus.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5a495-c8c4-4bf6-a3da-28a318c4b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_webcam(model=model,\n",
    "                 device=0,\n",
    "                 verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3206e8-fd39-406f-9486-5ef6fbbbf7be",
   "metadata": {},
   "source": [
    "# 4. Exportieren des Modells\n",
    "\n",
    "Wenn in Ihrer Produktionsumgebung das `.pt` - Format verwendet werden sollte, dann sind Sie nun fertig. Allerdings können die trainierten Modell auch in eine ganze Reihe von verschiedenen Formaten exportiert werden, sodass diese nahtlos in Ihrer Produktionsumgebung verwendet werden können:\n",
    "\n",
    "![Image](../beispielbilder/grafiken/formats.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30504ad3-939a-49a9-bcde-e0feba44df65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
